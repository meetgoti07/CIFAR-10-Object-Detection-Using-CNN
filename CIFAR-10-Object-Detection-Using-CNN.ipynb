{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79defb80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:03:08.510219Z",
     "iopub.status.busy": "2025-02-10T05:03:08.509891Z",
     "iopub.status.idle": "2025-02-10T05:03:36.436750Z",
     "shell.execute_reply": "2025-02-10T05:03:36.435581Z"
    },
    "papermill": {
     "duration": 27.931968,
     "end_time": "2025-02-10T05:03:36.438521",
     "exception": false,
     "start_time": "2025-02-10T05:03:08.506553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py7zr\r\n",
      "  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: texttable in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.7.0)\r\n",
      "Requirement already satisfied: pycryptodomex>=3.16.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (3.21.0)\r\n",
      "Collecting pyzstd>=0.15.9 (from py7zr)\r\n",
      "  Downloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\r\n",
      "Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\r\n",
      "  Downloading pyppmd-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\r\n",
      "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr)\r\n",
      "  Downloading pybcj-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\r\n",
      "Collecting multivolumefile>=0.2.3 (from py7zr)\r\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr)\r\n",
      "  Downloading inflate64-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\n",
      "Collecting brotli>=1.1.0 (from py7zr)\r\n",
      "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr) (5.9.5)\r\n",
      "Downloading py7zr-0.22.0-py3-none-any.whl (67 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.9/67.9 kB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.0/3.0 MB\u001B[0m \u001B[31m67.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading inflate64-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m93.3/93.3 kB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\r\n",
      "Downloading pybcj-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.6/49.6 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pyppmd-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m139.0/139.0 kB\u001B[0m \u001B[31m10.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m413.7/413.7 kB\u001B[0m \u001B[31m24.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: brotli, pyzstd, pyppmd, pybcj, multivolumefile, inflate64, py7zr\r\n",
      "Successfully installed brotli-1.1.0 inflate64-1.0.1 multivolumefile-0.2.3 py7zr-0.22.0 pybcj-1.0.3 pyppmd-1.1.1 pyzstd-0.16.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install py7zr\n",
    "\n",
    "from py7zr import unpack_7zarchive\n",
    "import shutil\n",
    "\n",
    "shutil.register_unpack_format('7zip', ['.7z'], unpack_7zarchive)\n",
    "\n",
    "shutil.unpack_archive('/kaggle/input/cifar-10/train.7z', '/kaggle/temp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf15cac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:03:36.447959Z",
     "iopub.status.busy": "2025-02-10T05:03:36.447561Z",
     "iopub.status.idle": "2025-02-10T05:03:40.148537Z",
     "shell.execute_reply": "2025-02-10T05:03:40.147576Z"
    },
    "papermill": {
     "duration": 3.707003,
     "end_time": "2025-02-10T05:03:40.150084",
     "exception": false,
     "start_time": "2025-02-10T05:03:36.443081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(type='cuda', index=0)\n",
    "else:\n",
    "    device = torch.device(type='cpu', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abf92fc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:03:40.158653Z",
     "iopub.status.busy": "2025-02-10T05:03:40.158229Z",
     "iopub.status.idle": "2025-02-10T05:03:40.196859Z",
     "shell.execute_reply": "2025-02-10T05:03:40.195946Z"
    },
    "papermill": {
     "duration": 0.044176,
     "end_time": "2025-02-10T05:03:40.198231",
     "exception": false,
     "start_time": "2025-02-10T05:03:40.154055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(\"/kaggle/input/cifar-10/trainLabels.csv\", header = 'infer')\n",
    "\n",
    "classes = train_labels['label'].unique()\n",
    "\n",
    "name2num = {}\n",
    "num2name = {}\n",
    "\n",
    "i=0\n",
    "\n",
    "for name in classes:\n",
    "    name2num[name] = i\n",
    "    i = i + 1\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    num2name[i] = classes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db6daeb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:03:40.206416Z",
     "iopub.status.busy": "2025-02-10T05:03:40.206119Z",
     "iopub.status.idle": "2025-02-10T05:03:44.320484Z",
     "shell.execute_reply": "2025-02-10T05:03:44.319783Z"
    },
    "papermill": {
     "duration": 4.1198,
     "end_time": "2025-02-10T05:03:44.321931",
     "exception": false,
     "start_time": "2025-02-10T05:03:40.202131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Normalize, Resize, Compose\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,imgpath, labelpath):\n",
    "        super().__init__()\n",
    "        self.imgpath = imgpath\n",
    "        self.labelpath = labelpath\n",
    "        self.labels = pd.read_csv(labelpath, header = 'infer')\n",
    "        self.transform = Compose([Resize((224,224), antialias = True), Normalize(mean = [0.485,0.456,0.406], std = [0.229,0.224,0.225])])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        finalpath = os.path.join(self.imgpath,str(idx+1)) + '.png'\n",
    "        img = read_image(finalpath)/255\n",
    "        img = self.transform(img)\n",
    "        label = self.labels.iloc[idx,1]\n",
    "        label = name2num[label]\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b1b8ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:03:44.330153Z",
     "iopub.status.busy": "2025-02-10T05:03:44.329825Z",
     "iopub.status.idle": "2025-02-10T05:03:44.343887Z",
     "shell.execute_reply": "2025-02-10T05:03:44.343313Z"
    },
    "papermill": {
     "duration": 0.019331,
     "end_time": "2025-02-10T05:03:44.345085",
     "exception": false,
     "start_time": "2025-02-10T05:03:44.325754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "traindataset = TrainDataset('/kaggle/temp/train','/kaggle/input/cifar-10/trainLabels.csv')\n",
    "\n",
    "batch_size = 64\n",
    "traindataloader = DataLoader(dataset = traindataset, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc8ddd05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:03:44.352737Z",
     "iopub.status.busy": "2025-02-10T05:03:44.352508Z",
     "iopub.status.idle": "2025-02-10T05:03:44.357140Z",
     "shell.execute_reply": "2025-02-10T05:03:44.356345Z"
    },
    "papermill": {
     "duration": 0.009848,
     "end_time": "2025-02-10T05:03:44.358457",
     "exception": false,
     "start_time": "2025-02-10T05:03:44.348609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
    "\n",
    "class Cifar10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pretrainednet = mobilenet_v3_large(weights = MobileNet_V3_Large_Weights.DEFAULT)\n",
    "        self.pretrainednet.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features = 960, out_features = 1280, bias = True),\n",
    "            nn.Hardswish(),\n",
    "            nn.Dropout(p = 0.2, inplace = True),\n",
    "            nn.Linear(in_features = 1280, out_features = 10, bias = True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.pretrainednet(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7cb6de0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:03:44.366642Z",
     "iopub.status.busy": "2025-02-10T05:03:44.366435Z",
     "iopub.status.idle": "2025-02-10T05:03:44.371900Z",
     "shell.execute_reply": "2025-02-10T05:03:44.371341Z"
    },
    "papermill": {
     "duration": 0.011017,
     "end_time": "2025-02-10T05:03:44.372949",
     "exception": false,
     "start_time": "2025-02-10T05:03:44.361932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader, model,loss_fn, optimizer):\n",
    "    model.train()\n",
    "    track_loss=0\n",
    "    num_correct=0\n",
    "    num_param=0\n",
    "    \n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        imgs=imgs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        pred=model(imgs)\n",
    "                    \n",
    "        loss=loss_fn(pred,labels)\n",
    "        track_loss+=loss.item()\n",
    "        num_correct+=(torch.argmax(pred,dim=1)==labels).type(torch.float).sum().item()\n",
    "        \n",
    "        running_loss=round(track_loss/(i+(imgs.shape[0]/batch_size)),2)\n",
    "        running_acc=round((num_correct/((i*batch_size+imgs.shape[0])))*100,2)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i%100==0:\n",
    "            print(\"Batch:\", i+1, \"/\",len(dataloader), \"Running Loss:\",running_loss, \"Running Accuracy:\",running_acc)\n",
    "            \n",
    "    epoch_loss=running_loss\n",
    "    epoch_acc=running_acc\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e45bd18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:03:44.380833Z",
     "iopub.status.busy": "2025-02-10T05:03:44.380637Z",
     "iopub.status.idle": "2025-02-10T05:27:15.444575Z",
     "shell.execute_reply": "2025-02-10T05:27:15.443589Z"
    },
    "papermill": {
     "duration": 1411.069431,
     "end_time": "2025-02-10T05:27:15.446001",
     "exception": false,
     "start_time": "2025-02-10T05:03:44.376570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-5c1a4163.pth\n",
      "100%|██████████| 21.1M/21.1M [00:00<00:00, 210MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 1\n",
      "Batch: 1 / 782 Running Loss: 2.3 Running Accuracy: 7.81\n",
      "Batch: 101 / 782 Running Loss: 1.06 Running Accuracy: 63.95\n",
      "Batch: 201 / 782 Running Loss: 0.92 Running Accuracy: 67.96\n",
      "Batch: 301 / 782 Running Loss: 0.87 Running Accuracy: 69.74\n",
      "Batch: 401 / 782 Running Loss: 0.83 Running Accuracy: 71.04\n",
      "Batch: 501 / 782 Running Loss: 0.81 Running Accuracy: 71.62\n",
      "Batch: 601 / 782 Running Loss: 0.8 Running Accuracy: 72.06\n",
      "Batch: 701 / 782 Running Loss: 0.79 Running Accuracy: 72.46\n",
      "Training: Epoch Loss: 0.78 Epoch Accuracy: 72.88\n",
      "--------------------------------------------------\n",
      "Epoch No: 2\n",
      "Batch: 1 / 782 Running Loss: 0.62 Running Accuracy: 76.56\n",
      "Batch: 101 / 782 Running Loss: 0.67 Running Accuracy: 76.67\n",
      "Batch: 201 / 782 Running Loss: 0.64 Running Accuracy: 77.15\n",
      "Batch: 301 / 782 Running Loss: 0.64 Running Accuracy: 77.58\n",
      "Batch: 401 / 782 Running Loss: 0.64 Running Accuracy: 77.62\n",
      "Batch: 501 / 782 Running Loss: 0.64 Running Accuracy: 77.62\n",
      "Batch: 601 / 782 Running Loss: 0.64 Running Accuracy: 77.63\n",
      "Batch: 701 / 782 Running Loss: 0.63 Running Accuracy: 77.69\n",
      "Training: Epoch Loss: 0.63 Epoch Accuracy: 77.8\n",
      "--------------------------------------------------\n",
      "Epoch No: 3\n",
      "Batch: 1 / 782 Running Loss: 0.57 Running Accuracy: 78.12\n",
      "Batch: 101 / 782 Running Loss: 0.6 Running Accuracy: 79.12\n",
      "Batch: 201 / 782 Running Loss: 0.57 Running Accuracy: 79.7\n",
      "Batch: 301 / 782 Running Loss: 0.57 Running Accuracy: 79.93\n",
      "Batch: 401 / 782 Running Loss: 0.57 Running Accuracy: 80.06\n",
      "Batch: 501 / 782 Running Loss: 0.56 Running Accuracy: 80.1\n",
      "Batch: 601 / 782 Running Loss: 0.56 Running Accuracy: 80.06\n",
      "Batch: 701 / 782 Running Loss: 0.56 Running Accuracy: 80.16\n",
      "Training: Epoch Loss: 0.56 Epoch Accuracy: 80.36\n",
      "--------------------------------------------------\n",
      "Epoch No: 4\n",
      "Batch: 1 / 782 Running Loss: 0.46 Running Accuracy: 79.69\n",
      "Batch: 101 / 782 Running Loss: 0.52 Running Accuracy: 81.61\n",
      "Batch: 201 / 782 Running Loss: 0.49 Running Accuracy: 82.36\n",
      "Batch: 301 / 782 Running Loss: 0.49 Running Accuracy: 82.67\n",
      "Batch: 401 / 782 Running Loss: 0.49 Running Accuracy: 82.81\n",
      "Batch: 501 / 782 Running Loss: 0.48 Running Accuracy: 83.0\n",
      "Batch: 601 / 782 Running Loss: 0.48 Running Accuracy: 83.01\n",
      "Batch: 701 / 782 Running Loss: 0.48 Running Accuracy: 83.2\n",
      "Training: Epoch Loss: 0.47 Epoch Accuracy: 83.34\n",
      "--------------------------------------------------\n",
      "Epoch No: 5\n",
      "Batch: 1 / 782 Running Loss: 0.49 Running Accuracy: 82.81\n",
      "Batch: 101 / 782 Running Loss: 0.43 Running Accuracy: 85.1\n",
      "Batch: 201 / 782 Running Loss: 0.41 Running Accuracy: 85.45\n",
      "Batch: 301 / 782 Running Loss: 0.4 Running Accuracy: 85.87\n",
      "Batch: 401 / 782 Running Loss: 0.4 Running Accuracy: 85.92\n",
      "Batch: 501 / 782 Running Loss: 0.4 Running Accuracy: 86.05\n",
      "Batch: 601 / 782 Running Loss: 0.39 Running Accuracy: 86.17\n",
      "Batch: 701 / 782 Running Loss: 0.39 Running Accuracy: 86.33\n",
      "Training: Epoch Loss: 0.39 Epoch Accuracy: 86.49\n",
      "--------------------------------------------------\n",
      "Epoch No: 6\n",
      "Batch: 1 / 782 Running Loss: 0.33 Running Accuracy: 85.94\n",
      "Batch: 101 / 782 Running Loss: 0.33 Running Accuracy: 88.47\n",
      "Batch: 201 / 782 Running Loss: 0.32 Running Accuracy: 88.44\n",
      "Batch: 301 / 782 Running Loss: 0.32 Running Accuracy: 88.77\n",
      "Batch: 401 / 782 Running Loss: 0.32 Running Accuracy: 88.91\n",
      "Batch: 501 / 782 Running Loss: 0.32 Running Accuracy: 89.11\n",
      "Batch: 601 / 782 Running Loss: 0.31 Running Accuracy: 89.26\n",
      "Batch: 701 / 782 Running Loss: 0.31 Running Accuracy: 89.39\n",
      "Training: Epoch Loss: 0.3 Epoch Accuracy: 89.54\n",
      "--------------------------------------------------\n",
      "Epoch No: 7\n",
      "Batch: 1 / 782 Running Loss: 0.23 Running Accuracy: 93.75\n",
      "Batch: 101 / 782 Running Loss: 0.26 Running Accuracy: 91.46\n",
      "Batch: 201 / 782 Running Loss: 0.25 Running Accuracy: 91.35\n",
      "Batch: 301 / 782 Running Loss: 0.25 Running Accuracy: 91.47\n",
      "Batch: 401 / 782 Running Loss: 0.24 Running Accuracy: 91.52\n",
      "Batch: 501 / 782 Running Loss: 0.24 Running Accuracy: 91.61\n",
      "Batch: 601 / 782 Running Loss: 0.24 Running Accuracy: 91.81\n",
      "Batch: 701 / 782 Running Loss: 0.23 Running Accuracy: 91.9\n",
      "Training: Epoch Loss: 0.23 Epoch Accuracy: 91.96\n",
      "--------------------------------------------------\n",
      "Epoch No: 8\n",
      "Batch: 1 / 782 Running Loss: 0.23 Running Accuracy: 92.19\n",
      "Batch: 101 / 782 Running Loss: 0.19 Running Accuracy: 93.72\n",
      "Batch: 201 / 782 Running Loss: 0.19 Running Accuracy: 93.63\n",
      "Batch: 301 / 782 Running Loss: 0.19 Running Accuracy: 93.31\n",
      "Batch: 401 / 782 Running Loss: 0.19 Running Accuracy: 93.52\n",
      "Batch: 501 / 782 Running Loss: 0.18 Running Accuracy: 93.53\n",
      "Batch: 601 / 782 Running Loss: 0.18 Running Accuracy: 93.7\n",
      "Batch: 701 / 782 Running Loss: 0.18 Running Accuracy: 93.72\n",
      "Training: Epoch Loss: 0.18 Epoch Accuracy: 93.74\n",
      "--------------------------------------------------\n",
      "Epoch No: 9\n",
      "Batch: 1 / 782 Running Loss: 0.25 Running Accuracy: 89.06\n",
      "Batch: 101 / 782 Running Loss: 0.15 Running Accuracy: 94.68\n",
      "Batch: 201 / 782 Running Loss: 0.15 Running Accuracy: 94.64\n",
      "Batch: 301 / 782 Running Loss: 0.15 Running Accuracy: 94.58\n",
      "Batch: 401 / 782 Running Loss: 0.15 Running Accuracy: 94.88\n",
      "Batch: 501 / 782 Running Loss: 0.15 Running Accuracy: 94.92\n",
      "Batch: 601 / 782 Running Loss: 0.14 Running Accuracy: 95.04\n",
      "Batch: 701 / 782 Running Loss: 0.14 Running Accuracy: 95.13\n",
      "Training: Epoch Loss: 0.14 Epoch Accuracy: 95.12\n",
      "--------------------------------------------------\n",
      "Epoch No: 10\n",
      "Batch: 1 / 782 Running Loss: 0.04 Running Accuracy: 100.0\n",
      "Batch: 101 / 782 Running Loss: 0.13 Running Accuracy: 95.2\n",
      "Batch: 201 / 782 Running Loss: 0.12 Running Accuracy: 95.48\n",
      "Batch: 301 / 782 Running Loss: 0.12 Running Accuracy: 95.54\n",
      "Batch: 401 / 782 Running Loss: 0.12 Running Accuracy: 95.64\n",
      "Batch: 501 / 782 Running Loss: 0.12 Running Accuracy: 95.72\n",
      "Batch: 601 / 782 Running Loss: 0.12 Running Accuracy: 95.85\n",
      "Batch: 701 / 782 Running Loss: 0.12 Running Accuracy: 95.92\n",
      "Training: Epoch Loss: 0.12 Epoch Accuracy: 95.93\n",
      "--------------------------------------------------\n",
      "Epoch No: 11\n",
      "Batch: 1 / 782 Running Loss: 0.17 Running Accuracy: 95.31\n",
      "Batch: 101 / 782 Running Loss: 0.11 Running Accuracy: 96.06\n",
      "Batch: 201 / 782 Running Loss: 0.1 Running Accuracy: 96.2\n",
      "Batch: 301 / 782 Running Loss: 0.11 Running Accuracy: 96.15\n",
      "Batch: 401 / 782 Running Loss: 0.1 Running Accuracy: 96.3\n",
      "Batch: 501 / 782 Running Loss: 0.1 Running Accuracy: 96.3\n",
      "Batch: 601 / 782 Running Loss: 0.1 Running Accuracy: 96.4\n",
      "Batch: 701 / 782 Running Loss: 0.1 Running Accuracy: 96.48\n",
      "Training: Epoch Loss: 0.1 Epoch Accuracy: 96.46\n",
      "--------------------------------------------------\n",
      "Epoch No: 12\n",
      "Batch: 1 / 782 Running Loss: 0.05 Running Accuracy: 100.0\n",
      "Batch: 101 / 782 Running Loss: 0.08 Running Accuracy: 97.18\n",
      "Batch: 201 / 782 Running Loss: 0.08 Running Accuracy: 97.22\n",
      "Batch: 301 / 782 Running Loss: 0.08 Running Accuracy: 97.25\n",
      "Batch: 401 / 782 Running Loss: 0.08 Running Accuracy: 97.18\n",
      "Batch: 501 / 782 Running Loss: 0.08 Running Accuracy: 97.16\n",
      "Batch: 601 / 782 Running Loss: 0.08 Running Accuracy: 97.16\n",
      "Batch: 701 / 782 Running Loss: 0.08 Running Accuracy: 97.2\n",
      "Training: Epoch Loss: 0.08 Epoch Accuracy: 97.19\n",
      "--------------------------------------------------\n",
      "Epoch No: 13\n",
      "Batch: 1 / 782 Running Loss: 0.09 Running Accuracy: 96.88\n",
      "Batch: 101 / 782 Running Loss: 0.07 Running Accuracy: 97.8\n",
      "Batch: 201 / 782 Running Loss: 0.07 Running Accuracy: 97.69\n",
      "Batch: 301 / 782 Running Loss: 0.07 Running Accuracy: 97.59\n",
      "Batch: 401 / 782 Running Loss: 0.07 Running Accuracy: 97.4\n",
      "Batch: 501 / 782 Running Loss: 0.07 Running Accuracy: 97.45\n",
      "Batch: 601 / 782 Running Loss: 0.07 Running Accuracy: 97.44\n",
      "Batch: 701 / 782 Running Loss: 0.07 Running Accuracy: 97.45\n",
      "Training: Epoch Loss: 0.07 Epoch Accuracy: 97.43\n",
      "--------------------------------------------------\n",
      "Epoch No: 14\n",
      "Batch: 1 / 782 Running Loss: 0.09 Running Accuracy: 95.31\n",
      "Batch: 101 / 782 Running Loss: 0.06 Running Accuracy: 97.68\n",
      "Batch: 201 / 782 Running Loss: 0.06 Running Accuracy: 97.64\n",
      "Batch: 301 / 782 Running Loss: 0.06 Running Accuracy: 97.71\n",
      "Batch: 401 / 782 Running Loss: 0.06 Running Accuracy: 97.67\n",
      "Batch: 501 / 782 Running Loss: 0.07 Running Accuracy: 97.57\n",
      "Batch: 601 / 782 Running Loss: 0.07 Running Accuracy: 97.61\n",
      "Batch: 701 / 782 Running Loss: 0.07 Running Accuracy: 97.58\n",
      "Training: Epoch Loss: 0.07 Epoch Accuracy: 97.59\n",
      "--------------------------------------------------\n",
      "Epoch No: 15\n",
      "Batch: 1 / 782 Running Loss: 0.03 Running Accuracy: 98.44\n",
      "Batch: 101 / 782 Running Loss: 0.07 Running Accuracy: 97.46\n",
      "Batch: 201 / 782 Running Loss: 0.07 Running Accuracy: 97.66\n",
      "Batch: 301 / 782 Running Loss: 0.07 Running Accuracy: 97.54\n",
      "Batch: 401 / 782 Running Loss: 0.07 Running Accuracy: 97.59\n",
      "Batch: 501 / 782 Running Loss: 0.07 Running Accuracy: 97.61\n",
      "Batch: 601 / 782 Running Loss: 0.06 Running Accuracy: 97.65\n",
      "Batch: 701 / 782 Running Loss: 0.06 Running Accuracy: 97.65\n",
      "Training: Epoch Loss: 0.06 Epoch Accuracy: 97.7\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Cifar10().to(device)\n",
    "\n",
    "for param in model.pretrainednet.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "learming_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = learming_rate)\n",
    "\n",
    "n_epochs = 15\n",
    "\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    print(\"Epoch No:\",i+1)\n",
    "    train_epoch_loss, train_epoch_acc=train_one_epoch(traindataloader,model,loss_fn,optimizer)\n",
    "    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23780ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:27:15.464857Z",
     "iopub.status.busy": "2025-02-10T05:27:15.464597Z",
     "iopub.status.idle": "2025-02-10T05:56:19.766474Z",
     "shell.execute_reply": "2025-02-10T05:56:19.765675Z"
    },
    "papermill": {
     "duration": 1744.312569,
     "end_time": "2025-02-10T05:56:19.767872",
     "exception": false,
     "start_time": "2025-02-10T05:27:15.455303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 1\n",
      "Batch: 1 / 782 Running Loss: 0.08 Running Accuracy: 96.88\n",
      "Batch: 101 / 782 Running Loss: 0.98 Running Accuracy: 75.99\n",
      "Batch: 201 / 782 Running Loss: 0.79 Running Accuracy: 79.24\n",
      "Batch: 301 / 782 Running Loss: 0.69 Running Accuracy: 80.97\n",
      "Batch: 401 / 782 Running Loss: 0.63 Running Accuracy: 82.29\n",
      "Batch: 501 / 782 Running Loss: 0.59 Running Accuracy: 83.26\n",
      "Batch: 601 / 782 Running Loss: 0.55 Running Accuracy: 84.07\n",
      "Batch: 701 / 782 Running Loss: 0.52 Running Accuracy: 84.76\n",
      "Training: Epoch Loss: 0.5 Epoch Accuracy: 85.24\n",
      "--------------------------------------------------\n",
      "Epoch No: 2\n",
      "Batch: 1 / 782 Running Loss: 0.2 Running Accuracy: 90.62\n",
      "Batch: 101 / 782 Running Loss: 0.26 Running Accuracy: 91.51\n",
      "Batch: 201 / 782 Running Loss: 0.26 Running Accuracy: 91.53\n",
      "Batch: 301 / 782 Running Loss: 0.25 Running Accuracy: 91.89\n",
      "Batch: 401 / 782 Running Loss: 0.24 Running Accuracy: 92.16\n",
      "Batch: 501 / 782 Running Loss: 0.23 Running Accuracy: 92.4\n",
      "Batch: 601 / 782 Running Loss: 0.23 Running Accuracy: 92.47\n",
      "Batch: 701 / 782 Running Loss: 0.22 Running Accuracy: 92.7\n",
      "Training: Epoch Loss: 0.22 Epoch Accuracy: 92.8\n",
      "--------------------------------------------------\n",
      "Epoch No: 3\n",
      "Batch: 1 / 782 Running Loss: 0.18 Running Accuracy: 95.31\n",
      "Batch: 101 / 782 Running Loss: 0.18 Running Accuracy: 94.18\n",
      "Batch: 201 / 782 Running Loss: 0.18 Running Accuracy: 94.26\n",
      "Batch: 301 / 782 Running Loss: 0.18 Running Accuracy: 94.17\n",
      "Batch: 401 / 782 Running Loss: 0.18 Running Accuracy: 94.15\n",
      "Batch: 501 / 782 Running Loss: 0.17 Running Accuracy: 94.27\n",
      "Batch: 601 / 782 Running Loss: 0.17 Running Accuracy: 94.32\n",
      "Batch: 701 / 782 Running Loss: 0.17 Running Accuracy: 94.43\n",
      "Training: Epoch Loss: 0.17 Epoch Accuracy: 94.42\n",
      "--------------------------------------------------\n",
      "Epoch No: 4\n",
      "Batch: 1 / 782 Running Loss: 0.05 Running Accuracy: 96.88\n",
      "Batch: 101 / 782 Running Loss: 0.16 Running Accuracy: 95.03\n",
      "Batch: 201 / 782 Running Loss: 0.16 Running Accuracy: 94.81\n",
      "Batch: 301 / 782 Running Loss: 0.15 Running Accuracy: 94.91\n",
      "Batch: 401 / 782 Running Loss: 0.15 Running Accuracy: 94.98\n",
      "Batch: 501 / 782 Running Loss: 0.15 Running Accuracy: 95.2\n",
      "Batch: 601 / 782 Running Loss: 0.14 Running Accuracy: 95.22\n",
      "Batch: 701 / 782 Running Loss: 0.14 Running Accuracy: 95.29\n",
      "Training: Epoch Loss: 0.14 Epoch Accuracy: 95.36\n",
      "--------------------------------------------------\n",
      "Epoch No: 5\n",
      "Batch: 1 / 782 Running Loss: 0.07 Running Accuracy: 98.44\n",
      "Batch: 101 / 782 Running Loss: 0.12 Running Accuracy: 96.07\n",
      "Batch: 201 / 782 Running Loss: 0.13 Running Accuracy: 95.68\n",
      "Batch: 301 / 782 Running Loss: 0.13 Running Accuracy: 95.7\n",
      "Batch: 401 / 782 Running Loss: 0.12 Running Accuracy: 95.89\n",
      "Batch: 501 / 782 Running Loss: 0.13 Running Accuracy: 95.7\n",
      "Batch: 601 / 782 Running Loss: 0.13 Running Accuracy: 95.7\n",
      "Batch: 701 / 782 Running Loss: 0.13 Running Accuracy: 95.69\n",
      "Training: Epoch Loss: 0.13 Epoch Accuracy: 95.68\n",
      "--------------------------------------------------\n",
      "Epoch No: 6\n",
      "Batch: 1 / 782 Running Loss: 0.05 Running Accuracy: 98.44\n",
      "Batch: 101 / 782 Running Loss: 0.12 Running Accuracy: 95.76\n",
      "Batch: 201 / 782 Running Loss: 0.13 Running Accuracy: 95.8\n",
      "Batch: 301 / 782 Running Loss: 0.12 Running Accuracy: 95.86\n",
      "Batch: 401 / 782 Running Loss: 0.12 Running Accuracy: 95.99\n",
      "Batch: 501 / 782 Running Loss: 0.11 Running Accuracy: 96.15\n",
      "Batch: 601 / 782 Running Loss: 0.11 Running Accuracy: 96.17\n",
      "Batch: 701 / 782 Running Loss: 0.11 Running Accuracy: 96.26\n",
      "Training: Epoch Loss: 0.11 Epoch Accuracy: 96.35\n",
      "--------------------------------------------------\n",
      "Epoch No: 7\n",
      "Batch: 1 / 782 Running Loss: 0.03 Running Accuracy: 98.44\n",
      "Batch: 101 / 782 Running Loss: 0.09 Running Accuracy: 96.83\n",
      "Batch: 201 / 782 Running Loss: 0.1 Running Accuracy: 96.67\n",
      "Batch: 301 / 782 Running Loss: 0.1 Running Accuracy: 96.68\n",
      "Batch: 401 / 782 Running Loss: 0.1 Running Accuracy: 96.6\n",
      "Batch: 501 / 782 Running Loss: 0.1 Running Accuracy: 96.54\n",
      "Batch: 601 / 782 Running Loss: 0.1 Running Accuracy: 96.53\n",
      "Batch: 701 / 782 Running Loss: 0.1 Running Accuracy: 96.52\n",
      "Training: Epoch Loss: 0.1 Epoch Accuracy: 96.54\n",
      "--------------------------------------------------\n",
      "Epoch No: 8\n",
      "Batch: 1 / 782 Running Loss: 0.06 Running Accuracy: 98.44\n",
      "Batch: 101 / 782 Running Loss: 0.08 Running Accuracy: 97.31\n",
      "Batch: 201 / 782 Running Loss: 0.09 Running Accuracy: 97.0\n",
      "Batch: 301 / 782 Running Loss: 0.09 Running Accuracy: 97.03\n",
      "Batch: 401 / 782 Running Loss: 0.09 Running Accuracy: 97.07\n",
      "Batch: 501 / 782 Running Loss: 0.09 Running Accuracy: 97.07\n",
      "Batch: 601 / 782 Running Loss: 0.09 Running Accuracy: 97.06\n",
      "Batch: 701 / 782 Running Loss: 0.09 Running Accuracy: 97.01\n",
      "Training: Epoch Loss: 0.09 Epoch Accuracy: 97.01\n",
      "--------------------------------------------------\n",
      "Epoch No: 9\n",
      "Batch: 1 / 782 Running Loss: 0.01 Running Accuracy: 100.0\n",
      "Batch: 101 / 782 Running Loss: 0.08 Running Accuracy: 97.01\n",
      "Batch: 201 / 782 Running Loss: 0.08 Running Accuracy: 97.18\n",
      "Batch: 301 / 782 Running Loss: 0.08 Running Accuracy: 97.29\n",
      "Batch: 401 / 782 Running Loss: 0.08 Running Accuracy: 97.2\n",
      "Batch: 501 / 782 Running Loss: 0.08 Running Accuracy: 97.15\n",
      "Batch: 601 / 782 Running Loss: 0.08 Running Accuracy: 97.2\n",
      "Batch: 701 / 782 Running Loss: 0.08 Running Accuracy: 97.25\n",
      "Training: Epoch Loss: 0.08 Epoch Accuracy: 97.25\n",
      "--------------------------------------------------\n",
      "Epoch No: 10\n",
      "Batch: 1 / 782 Running Loss: 0.06 Running Accuracy: 98.44\n",
      "Batch: 101 / 782 Running Loss: 0.07 Running Accuracy: 97.59\n",
      "Batch: 201 / 782 Running Loss: 0.08 Running Accuracy: 97.36\n",
      "Batch: 301 / 782 Running Loss: 0.08 Running Accuracy: 97.4\n",
      "Batch: 401 / 782 Running Loss: 0.08 Running Accuracy: 97.41\n",
      "Batch: 501 / 782 Running Loss: 0.07 Running Accuracy: 97.48\n",
      "Batch: 601 / 782 Running Loss: 0.07 Running Accuracy: 97.54\n",
      "Batch: 701 / 782 Running Loss: 0.07 Running Accuracy: 97.55\n",
      "Training: Epoch Loss: 0.07 Epoch Accuracy: 97.58\n",
      "--------------------------------------------------\n",
      "Epoch No: 11\n",
      "Batch: 1 / 782 Running Loss: 0.06 Running Accuracy: 95.31\n",
      "Batch: 101 / 782 Running Loss: 0.09 Running Accuracy: 96.92\n",
      "Batch: 201 / 782 Running Loss: 0.08 Running Accuracy: 97.42\n",
      "Batch: 301 / 782 Running Loss: 0.08 Running Accuracy: 97.34\n",
      "Batch: 401 / 782 Running Loss: 0.08 Running Accuracy: 97.47\n",
      "Batch: 501 / 782 Running Loss: 0.08 Running Accuracy: 97.43\n",
      "Batch: 601 / 782 Running Loss: 0.08 Running Accuracy: 97.33\n",
      "Batch: 701 / 782 Running Loss: 0.08 Running Accuracy: 97.34\n",
      "Training: Epoch Loss: 0.08 Epoch Accuracy: 97.38\n",
      "--------------------------------------------------\n",
      "Epoch No: 12\n",
      "Batch: 1 / 782 Running Loss: 0.08 Running Accuracy: 96.88\n",
      "Batch: 101 / 782 Running Loss: 0.05 Running Accuracy: 98.07\n",
      "Batch: 201 / 782 Running Loss: 0.07 Running Accuracy: 97.68\n",
      "Batch: 301 / 782 Running Loss: 0.07 Running Accuracy: 97.73\n",
      "Batch: 401 / 782 Running Loss: 0.07 Running Accuracy: 97.76\n",
      "Batch: 501 / 782 Running Loss: 0.07 Running Accuracy: 97.8\n",
      "Batch: 601 / 782 Running Loss: 0.07 Running Accuracy: 97.75\n",
      "Batch: 701 / 782 Running Loss: 0.07 Running Accuracy: 97.78\n",
      "Training: Epoch Loss: 0.06 Epoch Accuracy: 97.84\n",
      "--------------------------------------------------\n",
      "Epoch No: 13\n",
      "Batch: 1 / 782 Running Loss: 0.01 Running Accuracy: 100.0\n",
      "Batch: 101 / 782 Running Loss: 0.06 Running Accuracy: 97.99\n",
      "Batch: 201 / 782 Running Loss: 0.06 Running Accuracy: 98.06\n",
      "Batch: 301 / 782 Running Loss: 0.06 Running Accuracy: 98.01\n",
      "Batch: 401 / 782 Running Loss: 0.06 Running Accuracy: 97.97\n",
      "Batch: 501 / 782 Running Loss: 0.06 Running Accuracy: 97.95\n",
      "Batch: 601 / 782 Running Loss: 0.06 Running Accuracy: 97.95\n",
      "Batch: 701 / 782 Running Loss: 0.06 Running Accuracy: 97.98\n",
      "Training: Epoch Loss: 0.06 Epoch Accuracy: 97.94\n",
      "--------------------------------------------------\n",
      "Epoch No: 14\n",
      "Batch: 1 / 782 Running Loss: 0.01 Running Accuracy: 100.0\n",
      "Batch: 101 / 782 Running Loss: 0.06 Running Accuracy: 98.1\n",
      "Batch: 201 / 782 Running Loss: 0.05 Running Accuracy: 98.21\n",
      "Batch: 301 / 782 Running Loss: 0.06 Running Accuracy: 98.13\n",
      "Batch: 401 / 782 Running Loss: 0.05 Running Accuracy: 98.22\n",
      "Batch: 501 / 782 Running Loss: 0.05 Running Accuracy: 98.2\n",
      "Batch: 601 / 782 Running Loss: 0.05 Running Accuracy: 98.21\n",
      "Batch: 701 / 782 Running Loss: 0.05 Running Accuracy: 98.21\n",
      "Training: Epoch Loss: 0.05 Epoch Accuracy: 98.26\n",
      "--------------------------------------------------\n",
      "Epoch No: 15\n",
      "Batch: 1 / 782 Running Loss: 0.02 Running Accuracy: 100.0\n",
      "Batch: 101 / 782 Running Loss: 0.05 Running Accuracy: 98.41\n",
      "Batch: 201 / 782 Running Loss: 0.06 Running Accuracy: 98.24\n",
      "Batch: 301 / 782 Running Loss: 0.06 Running Accuracy: 98.16\n",
      "Batch: 401 / 782 Running Loss: 0.06 Running Accuracy: 98.14\n",
      "Batch: 501 / 782 Running Loss: 0.06 Running Accuracy: 98.21\n",
      "Batch: 601 / 782 Running Loss: 0.06 Running Accuracy: 98.22\n",
      "Batch: 701 / 782 Running Loss: 0.06 Running Accuracy: 98.23\n",
      "Training: Epoch Loss: 0.06 Epoch Accuracy: 98.21\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for param in model.pretrainednet.features.parameters():\n",
    "    param.requires_grad=True\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    print(\"Epoch No:\",i+1)\n",
    "    train_epoch_loss, train_epoch_acc=train_one_epoch(traindataloader,model,loss_fn,optimizer)\n",
    "    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13c2a85d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:56:19.797197Z",
     "iopub.status.busy": "2025-02-10T05:56:19.796936Z",
     "iopub.status.idle": "2025-02-10T05:58:29.772973Z",
     "shell.execute_reply": "2025-02-10T05:58:29.772262Z"
    },
    "papermill": {
     "duration": 129.992197,
     "end_time": "2025-02-10T05:58:29.774646",
     "exception": false,
     "start_time": "2025-02-10T05:56:19.782449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#unpacking test images, there are 3 lacs images. This will take some time\n",
    "shutil.unpack_archive('/kaggle/input/cifar-10/test.7z', '/kaggle/temp/')\n",
    "\n",
    "#unregister unpack format, we are done with it\n",
    "shutil.unregister_unpack_format('7zip')#, ['.7z'], unpack_7zarchive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad4c879c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:58:29.804110Z",
     "iopub.status.busy": "2025-02-10T05:58:29.803890Z",
     "iopub.status.idle": "2025-02-10T05:58:30.022192Z",
     "shell.execute_reply": "2025-02-10T05:58:30.021570Z"
    },
    "papermill": {
     "duration": 0.234237,
     "end_time": "2025-02-10T05:58:30.023688",
     "exception": false,
     "start_time": "2025-02-10T05:58:29.789451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, imgpath):\n",
    "        super().__init__()\n",
    "        self.imgpath=imgpath\n",
    "        _,_,self.files=next(os.walk(self.imgpath))\n",
    "        self.length=len(self.files)\n",
    "        self.transform=Compose([Resize((224,224), antialias=True), Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        finalpath=os.path.join(self.imgpath,str(idx+1))+'.png'\n",
    "        img=read_image(finalpath)/255.0\n",
    "        img=self.transform(img)\n",
    "        return img\n",
    "\n",
    "testdataset=TestDataset('/kaggle/temp/test/')\n",
    "testdataloader=DataLoader(dataset=testdataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1ebb9a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:58:30.052711Z",
     "iopub.status.busy": "2025-02-10T05:58:30.052484Z",
     "iopub.status.idle": "2025-02-10T05:58:30.057240Z",
     "shell.execute_reply": "2025-02-10T05:58:30.056641Z"
    },
    "papermill": {
     "duration": 0.020511,
     "end_time": "2025-02-10T05:58:30.058438",
     "exception": false,
     "start_time": "2025-02-10T05:58:30.037927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval(dataloader, model,loss_fn, path):\n",
    "    model.eval()\n",
    "    data=pd.read_csv(path)\n",
    "    with torch.no_grad():\n",
    "        for i, imgs in enumerate(dataloader):\n",
    "            finalbatchpred=np.zeros(imgs.shape[0],dtype='object')\n",
    "            imgs=imgs.to(device)\n",
    "            pred=model(imgs)\n",
    "            \n",
    "            pred=torch.argmax(pred,dim=1).type(torch.int).cpu()\n",
    "            for j,p in enumerate(pred):\n",
    "                finalbatchpred[j]=num2name[p.item()]\n",
    "            data.iloc[i*batch_size:i*batch_size+batch_size ,1]=finalbatchpred\n",
    "    \n",
    "    data.to_csv('submission.csv', index=False)\n",
    "    data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cfc638f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:58:30.086839Z",
     "iopub.status.busy": "2025-02-10T05:58:30.086638Z",
     "iopub.status.idle": "2025-02-10T06:06:17.180026Z",
     "shell.execute_reply": "2025-02-10T06:06:17.179340Z"
    },
    "papermill": {
     "duration": 467.109209,
     "end_time": "2025-02-10T06:06:17.181568",
     "exception": false,
     "start_time": "2025-02-10T05:58:30.072359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval(testdataloader, model,loss_fn, '/kaggle/input/cifar-10/sampleSubmission.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 46718,
     "sourceId": 3649,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3794.090464,
   "end_time": "2025-02-10T06:06:19.223849",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-10T05:03:05.133385",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
